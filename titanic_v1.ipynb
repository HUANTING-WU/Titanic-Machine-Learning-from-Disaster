{
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "1MHnHZ5d_QNg",
        "_uuid": "2a5008ee31a7f9aa264239097c79632a313c5ff2"
      },
      "cell_type": "markdown",
      "source": "## Utility Functions Load"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bef9dc3dbb4a3469e9a7f9d364ab07ae5aec2fbb"
      },
      "cell_type": "code",
      "source": "# %load utilities.py\ndef plot_distribution(data):\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    from scipy import stats\n\n    plt.figure()\n    sns.distplot(data, fit=stats.norm);\n    mean, std = stats.norm.fit(data)\n    print('mean = {:.4f}\\nstd = {:.4f}\\nskewness = {:.4f}\\nkurtosis = {:.4f}'\n          .format(mean, std, data.skew(), data.kurtosis()))\n    plt.figure()\n    stats.probplot(data, plot=plt);\n\ndef describe_numerical(data):\n    print('mean:', data.mean())\n    print('median:', data.median())\n    print('mode:', data.mode().values[0])\n    print(data.describe())\n\ndef missing_value(data):\n    print('missing value number:', data.isnull().sum())\n    print('missing value percentage:', data.isnull().sum()/len(data))\n\ndef submit(test_X_og, pred_y):\n    import pandas as pd\n\n    submit = pd.DataFrame(data=[test_X_og.index, pred_y]).T\n    submit.columns = ['PassengerId', 'Survived']\n    submit = submit.astype('int32')\n    submit.to_csv('submit.csv', index=False)\n\ndef gridsearchcv(model, param_grid, train_X, train_Y, dev_X, dev_Y):\n    from sklearn.model_selection import (cross_val_score, GridSearchCV, KFold)\n    from sklearn.metrics import accuracy_score\n\n    model = GridSearchCV(model, param_grid=param_grid, scoring='accuracy',\n                        cv=KFold(n_splits=5, shuffle=True, random_state=None))\n    model.fit(train_X, train_Y)\n    print('grid search best parameters:', model.best_params_)\n    print('grid search best scores: {:.4f}'.format(model.best_score_))\n\n    train_scores = cross_val_score(model, train_X, train_Y, scoring='accuracy',\n                                cv=KFold(n_splits=5, shuffle=True, random_state=None))\n    train_score = train_scores.mean()\n    print('cv score: {:.4f}'.format(train_score))\n\n    pred_y = model.predict(dev_X)\n    dev_score = accuracy_score(dev_Y, pred_y)\n    print('dev score: {:.4f}'.format(dev_score))\n\n    return model\n\ndef plot_result(history):\n    import matplotlib.pyplot as plt\n\n    print('train set loss: {:.4f}'.format(history.history['loss'][-1]))\n    print('dev set loss: {:.4f}'.format(history.history['val_loss'][-1]))\n    print('train set accuracy: {:.4f}'.format(history.history['binary_accuracy'][-1]))\n    print('dev set accuracy: {:.4f}'.format(history.history['val_binary_accuracy'][-1]))\n\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train Loss', 'Dev Loss'], loc='upper right')\n    plt.show()\n\n    plt.plot(history.history['binary_accuracy'])\n    plt.plot(history.history['val_binary_accuracy'])\n    plt.title('Model Accuracy')\n    plt.ylabel('Loss Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train Accuracy', 'Dev Accuracy'], loc='upper right')\n    plt.show()\n\ndef create_nn(train_X, train_Y, dev_X, dev_Y, l1, l2, lr, batch_size, epochs):\n    from keras.callbacks import (History, EarlyStopping)\n    from keras.models import Sequential\n    from keras.layers import Dense, Dropout\n    from keras import losses\n    from keras import metrics\n    from keras import optimizers\n    from keras import initializers\n    from keras import regularizers\n\n    model = Sequential()\n\n    model.add(Dense(64, activation='relu',\n              kernel_initializer=initializers.he_normal(seed=42),\n              bias_initializer=initializers.Zeros(),\n              kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n              bias_regularizer=regularizers.l1_l2(l1=l1, l2=l2)))\n\n    model.add(Dropout(rate=0.5, seed=42))\n\n    model.add(Dense(32, activation='relu',\n              kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2),\n              bias_regularizer=regularizers.l1_l2(l1=l1, l2=l2)))\n\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.compile(optimizer=optimizers.Adam(lr=lr),\n              loss=losses.binary_crossentropy,\n              metrics = [metrics.binary_accuracy])\n\n    history = History()\n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n    model.fit(train_X, train_Y, validation_data=[dev_X, dev_Y], shuffle=True, verbose=0,\n                batch_size=batch_size, epochs=epochs, callbacks=[history, early_stop])\n\n    return model, history, early_stop\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "719b2c1eb5e311a12f06036979cffc99d98abf40"
      },
      "cell_type": "markdown",
      "source": "## Data Load"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1153
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 1200,
          "status": "error",
          "timestamp": 1553303908600,
          "user": {
            "displayName": "colab hok001",
            "photoUrl": "",
            "userId": "08064250200332094494"
          },
          "user_tz": 0
        },
        "id": "mMHT659uCTbQ",
        "outputId": "d9a4c83b-5db5-40f7-d088-c75fd68ea56b",
        "trusted": true,
        "_uuid": "d3aa5e36bf257a2e066232d54c630d76e3b4ca68"
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom scipy import stats\n# from utilities import *\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport re\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.model_selection import (train_test_split, cross_val_score, GridSearchCV, KFold)\nfrom sklearn import (preprocessing, feature_extraction, linear_model, svm, neighbors, \n                     gaussian_process, tree, ensemble)\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nimport pickle\nimport warnings\nwarnings.filterwarnings('ignore')\n%load_ext autoreload\n%autoreload\n\ntrain_og = pd.read_csv('../input/train.csv', index_col=0)\ntrain_og = train_og.copy()\ntest_X_og = pd.read_csv('../input/test.csv', index_col=0)\ntest_X_og = test_X_og.copy()\n\nprint('train set shape:', train_og.shape)\nprint('test set shape:', test_X_og.shape)\n\ntrain_X_og, train_Y_og = train_og[train_og.columns[1:]], train_og[train_og.columns[0]]\n\nX_og = pd.concat([train_X_og, test_X_og])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xbbS2QZy_QNg",
        "_uuid": "801debf050da0ea6018006cba6b7d787f039c3ae"
      },
      "cell_type": "markdown",
      "source": "## Feature Classification"
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "O2lTLdBl_QNg",
        "trusted": true,
        "_uuid": "af4bd817ed3437a940eddc43987e8805958260f1"
      },
      "cell_type": "code",
      "source": "X_og = X_og.rename(columns={'Pclass' : 'class', 'Name' : 'full name', \n                           'Sex' : 'sex', 'Age' : 'age', 'SibSp' : 'family size 01', \n                           'Parch' : 'family size 02', 'Ticket' : 'ticket', \n                           'Fare' : 'fare', 'Cabin' : 'cabin class number', 'Embarked' : 'embarked'})\n\n# print(X_og.columns)\n\ncategorical = ['class', 'full name', 'sex', 'ticket', 'cabin class number', 'embarked']\nnumerical = ['age', 'fare', 'family size 01', 'family size 02']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bjbpuD4s_QPE",
        "_uuid": "585927f04dd10705a50d0e0fcf5489fb6f827b69"
      },
      "cell_type": "markdown",
      "source": "## Check Missing Values "
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "X0Xd-oJ4_QPE",
        "trusted": true,
        "_uuid": "c41bc4d21b8b20b634921c0454c1af1f19e3f166"
      },
      "cell_type": "code",
      "source": "# print('train_Y missing value:', train_Y_og.isnull().sum())\n# print()\n# print('X_og missing value number:')\n# print((X_og.isnull().sum()).sort_values(ascending=False)[:10])\n# print()\n# print('X_og missing value percentage:')\n# print((X_og.isnull().sum()/len(X_og)).sort_values(ascending=False)[:10])\nX_fill = X_og.copy()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "yPpT8Ibi_QPE",
        "_uuid": "a0eb881571c28440383d8317edc41059581a98ed"
      },
      "cell_type": "markdown",
      "source": "## 'cabin class number' Feature Missing Values"
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8D-lJSxi_QPE",
        "trusted": true,
        "_uuid": "0f093b67111d97241e2e60f78280187ad31c2f25"
      },
      "cell_type": "code",
      "source": "# missing_value(X_og['cabin class number'])\n\nX_fill['cabin class number'] = X_fill['cabin class number'].fillna('None')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ix9sFH9O_QPE",
        "_uuid": "dd61eae75c4de3d55b443fc885135fe4d47f4280"
      },
      "cell_type": "markdown",
      "source": "## 'age' Feature Missing Values "
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "evDUfJ7t_QPE",
        "trusted": true,
        "_uuid": "c75938c4fac43337c35535e0c641e7f008e043dd"
      },
      "cell_type": "code",
      "source": "# missing_value(X_og['age'])\n\n# describe_numerical(X_og['age'])\n\nX_fill['age'] = X_fill['age'].fillna(X_fill['age'].median())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DXCpSPpC_QPE",
        "_uuid": "dd37ac72a33363186523e42ac5734ec44f6a5dde"
      },
      "cell_type": "markdown",
      "source": "## 'embarked' & 'fare' Feature Missing Values"
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4XRv8XMU_QPE",
        "trusted": true,
        "_uuid": "e33714737c4d164de85742c2ce73bb361747ba86"
      },
      "cell_type": "code",
      "source": "# missing_value(X_og['embarked'])\n\nX_fill['embarked'].describe()\n\nX_fill['embarked'] = X_fill['embarked'].fillna(X_fill['embarked'].describe()['top'])\n\n# missing_value(X_og['fare'])\n\n# describe_numerical(X_og['fare'])\n\nX_fill['fare'] = X_fill['fare'].fillna(X_fill['fare'].median())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Y3sU9AAF_QPE",
        "_uuid": "f4c442363e421105c46ed47a572ed56c32009918"
      },
      "cell_type": "markdown",
      "source": "## Check Filled Missing Values"
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RNj-UQLm_QPE",
        "trusted": true,
        "_uuid": "d8cfff868227d4ac5d7e4cd7b787642d1c3445c2"
      },
      "cell_type": "code",
      "source": "# print('X_fill missing value number:')\n# print((X_fill.isnull().sum()).sort_values(ascending=False)[:10])\n# print('X_fill missing value percentage:')\n# print((X_fill.isnull().sum()/len(X_fill)).sort_values(ascending=False)[:10])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_poIk17N_QPE",
        "_uuid": "8a5c7e8636c59c4df4c5bfee971a9aab17052f43"
      },
      "cell_type": "markdown",
      "source": "## Numerical Feature Skewness & Kurtosis"
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oY99FqLn_QPE",
        "outputId": "3bc2828f-3c99-4531-86e2-276ae95a7395",
        "trusted": true,
        "_uuid": "57ec4c1f79d6327b718a703740a4763356fad3ed"
      },
      "cell_type": "code",
      "source": "# for i in numerical: print(i+' skewness:', X_og[i].skew())\n\nX_fill['fare'] = np.log1p(X_fill['fare'])\n\n# print('fare skewness:', X_og['fare'].skew())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "432e6e0902e50e0575f1c38fe628dc47b8894d3d"
      },
      "cell_type": "markdown",
      "source": "## Drop 'ticket' Feature"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "93781d41173d22262afbc8fcb343492dcf5f3a6e"
      },
      "cell_type": "code",
      "source": "X_fill = X_fill.drop('ticket', axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d96786fd9668d770cc4a26c92dab80eccdcef7d0"
      },
      "cell_type": "markdown",
      "source": "## Add Feature 'cabin class' & Drop 'cabin class number' Feature"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e213e6aa34934755942b7fc510f38bba94f26f2"
      },
      "cell_type": "code",
      "source": "X_fill['cabin class'] = list(X_fill['cabin class number'].str[0])\n\nX_fill = X_fill.drop('cabin class number', axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1f225de900700a092c739b45de03db4d823bc7d0"
      },
      "cell_type": "markdown",
      "source": "## Add Feature 'family size' & Drop 'family size 01/02' Features"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9939e0f28e4d741c54b9ac0c9de8b4cf1d9989f2"
      },
      "cell_type": "code",
      "source": "X_fill['family size'] = X_fill['family size 01'] + X_fill['family size 02'] + 1\n\nX_fill = X_fill.drop(['family size 01', 'family size 02'], axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b836f9c87ecbc4957a10bd3e71fa5ff4acfb57ef"
      },
      "cell_type": "markdown",
      "source": "## Add Feature 'alone'"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "663d3edf1361bf5d31bd7edf51150102c450a932"
      },
      "cell_type": "code",
      "source": "X_fill['alone'] = np.where(X_fill['family size'] == 1, 1, 0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e7bd55446f9839e0df50de417d9665f47cbe4038"
      },
      "cell_type": "markdown",
      "source": "## Add Feature 'honorific' & Drop 'full name' Feature"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c0a1691338dae2da0425de59ccad6bfdaac8e327"
      },
      "cell_type": "code",
      "source": "honorific = [i[0] for i in X_fill['full name'].str.split(', ', expand=True)[1].str.split('.')]\n\nX_fill['honorific'] = honorific\n\nX_fill = X_fill.drop('full name', axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "F3EMrZ9k_QQo",
        "_uuid": "6dfd8abf4223a08442b841432a79180a29f20ed5"
      },
      "cell_type": "markdown",
      "source": "## Feature Value Transformation"
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3t3pGAst_QQo",
        "outputId": "3cd08777-89d6-435d-9e35-05d2285e10e5",
        "trusted": true,
        "_uuid": "1ecabeba3840ed1cbbb9ded6a05a7ce5db60455e"
      },
      "cell_type": "code",
      "source": "X_pre_transform = X_fill.copy()\n\n# print(X_pre_transform.columns)\n\nnominal = ['sex', 'alone', 'honorific']\nordinal = ['class', 'embarked', 'cabin class']\ndiscrete = ['family size']\ncontinuous = ['age', 'fare']\n\nmapper = DataFrameMapper([\n    (nominal, preprocessing.OneHotEncoder(sparse=False)), \n    (ordinal, preprocessing.OrdinalEncoder()), \n    (discrete, preprocessing.LabelEncoder()), \n    (continuous, preprocessing.StandardScaler())], \n    df_out=True)\n\nX = mapper.fit_transform(X_pre_transform)\n\n# print('X feature set shape:', X.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "id3-Q-Hf_QQo",
        "_uuid": "8ba442ed777660b93897f1edf88ec96d83d3dd54"
      },
      "cell_type": "markdown",
      "source": "## Create Train, Dev, Test Sets"
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SlhHqHRi_QQo",
        "trusted": true,
        "_uuid": "853e4b585e433680dd33ac723de367047a458bca"
      },
      "cell_type": "code",
      "source": "train_X = X.loc[train_X_og.index].values\ntest_X = X.loc[test_X_og.index].values\n\ntrain_Y = train_Y_og.values\n\ntrain_X, dev_X, train_Y, dev_Y = train_test_split(train_X, train_Y, random_state=42)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "257087cfacafaceea06f2dbc61c8c5f259fac3f5"
      },
      "cell_type": "markdown",
      "source": "## Model 01 - LogisticRegression L1 Regularization"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "144402b453a1cbe389c67d43157903d0f548527c"
      },
      "cell_type": "code",
      "source": "model1 = linear_model.LogisticRegression(penalty='l1', multi_class='ovr', max_iter=1000)\n\ngrid1 = {'C' : [1, 1.5, 2], \n         'solver' : ['liblinear', 'saga']}\n\nmodel1 = gridsearchcv(model1, grid1, train_X, train_Y, dev_X, dev_Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1a03ba2b10508b30bea7236e0c9243645015e962"
      },
      "cell_type": "code",
      "source": "pickle.dump(model1, open('model1.sav', 'wb'))\nmodel1_load = pickle.load(open('model1.sav', 'rb'))\ny1 = model1_load.predict(test_X)\ny1_save = pd.DataFrame(data=[test_X_og.index, y1]).T\ny1_save.columns = ['PassengerId', 'Survived']\ny1_save = y1_save.astype('int32')\ny1_save.to_csv('y1.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "N3vVM0dX_QQo",
        "_uuid": "5e422c3da1f4a0f1815fe592faaba58dd69b31b3"
      },
      "cell_type": "markdown",
      "source": "## Model 02 - LogisticRegression L2 Regularization"
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RHm_zod-_QQo",
        "trusted": true,
        "_uuid": "b09d29fe33809a442bce15f606500b30477d71d4"
      },
      "cell_type": "code",
      "source": "model2 = linear_model.LogisticRegression(penalty='l2', max_iter=1000)\n\ngrid2 = {'C' : [1, 1.5, 2], \n         'solver' : ['newton-cg', 'lbfgs', 'sag']}\n\nmodel2 = gridsearchcv(model2, grid2, train_X, train_Y, dev_X, dev_Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "300bf2d307f11779a4b64d1221ef4c80ec525504"
      },
      "cell_type": "code",
      "source": "pickle.dump(model2, open('model2.sav', 'wb'))\nmodel2_load = pickle.load(open('model2.sav', 'rb'))\ny2 = model2_load.predict(test_X)\ny2_save = pd.DataFrame(data=[test_X_og.index, y2]).T\ny2_save.columns = ['PassengerId', 'Survived']\ny2_save = y2_save.astype('int32')\ny2_save.to_csv('y2.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9d4030d0f45655a0c7a5f61ac8b217875f12a89b"
      },
      "cell_type": "markdown",
      "source": "## Model 03 - SupportVectorMachine "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "956a2b1e345cb62dda85bf745cb0d387436fadf4"
      },
      "cell_type": "code",
      "source": "model3 = svm.SVC(decision_function_shape='ovr', random_state=42)\n\ngrid3 = {'C' : [5, 5.5, 6], \n         'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'], \n         'degree' : [2, 3]}\n\nmodel3 = gridsearchcv(model3, grid3, train_X, train_Y, dev_X, dev_Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e6c351a26c6342f0d7d9707985873220cefb13e"
      },
      "cell_type": "code",
      "source": "pickle.dump(model3, open('model3.sav', 'wb'))\nmodel3_load = pickle.load(open('model3.sav', 'rb'))\ny3 = model3_load.predict(test_X)\ny3_save = pd.DataFrame(data=[test_X_og.index, y3]).T\ny3_save.columns = ['PassengerId', 'Survived']\ny3_save = y3_save.astype('int32')\ny3_save.to_csv('y3.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "24c4cd3e5ab3764cb15dc10d51b6dd04a99bea7d"
      },
      "cell_type": "markdown",
      "source": "## Model 04 - NearestNeighbors"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "abd272688f4c3fff0cddedad8dc79fb410156431"
      },
      "cell_type": "code",
      "source": "model4 = neighbors.KNeighborsClassifier()\n\ngrid4 = {'n_neighbors' : [3, 4, 5, 6, 7, 8, 9], \n         'weights' : ['uniform', 'distance'], \n         'algorithm' : ['ball_tree', 'kd_tree', 'brute'], \n         'leaf_size' : [20, 30, 40, 50, 60], \n         'p' : [1, 2]}\n\nmodel4 = gridsearchcv(model4, grid4, train_X, train_Y, dev_X, dev_Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "87f59e02d8115199e05926725b1b198f2dcfbb70"
      },
      "cell_type": "code",
      "source": "pickle.dump(model4, open('model4.sav', 'wb'))\nmodel4_load = pickle.load(open('model4.sav', 'rb'))\ny4 = model4_load.predict(test_X)\ny4_save = pd.DataFrame(data=[test_X_og.index, y4]).T\ny4_save.columns = ['PassengerId', 'Survived']\ny4_save = y4_save.astype('int32')\ny4_save.to_csv('y4.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f58879a344a7afcde22e19582d817e2f39fb7db7"
      },
      "cell_type": "markdown",
      "source": "## Model 05 - DecisionTree"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "32574512ec569ebab00726af05f3f4bf1b6c895a"
      },
      "cell_type": "code",
      "source": "model5 = tree.DecisionTreeClassifier(random_state=42)\n\ngrid5 = {'criterion' : ['gini', 'entropy'], \n        'splitter' : ['best', 'random'], \n        'max_depth' : [2, 3, 4, 5, 6, 7, 8, 9], \n        'min_samples_split' : [2, 3, 4, 5, 6, 7, 8, 9], \n        'min_samples_leaf' : [1, 2, 3, 4, 5, 6, 7, 8, 9]}\n\nmodel5 = gridsearchcv(model5, grid5, train_X, train_Y, dev_X, dev_Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "01642f552e81f370f32a75df4bfc3f52276c7a36"
      },
      "cell_type": "code",
      "source": "pickle.dump(model5, open('model5.sav', 'wb'))\nmodel5_load = pickle.load(open('model5.sav', 'rb'))\ny5 = model5_load.predict(test_X)\ny5_save = pd.DataFrame(data=[test_X_og.index, y5]).T\ny5_save.columns = ['PassengerId', 'Survived']\ny5_save = y5_save.astype('int32')\ny5_save.to_csv('y5.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d3084edd0673522d13f6c9e5af737fc0c27185c6"
      },
      "cell_type": "markdown",
      "source": "## Model 06 - RandomForestClassifier"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b46c709f8a3df910841732f28830635be98f24b8"
      },
      "cell_type": "code",
      "source": "model6 = ensemble.RandomForestClassifier(random_state=42)\n\ngrid6 = {'n_estimators' : [10, 20, 30, 40, 50], \n        'criterion' : ['gini', 'entropy'], \n        'max_depth' : [6, 7, 8], \n        'min_samples_split' : [2, 3, 4, 5], \n        'min_samples_leaf' : [1, 2, 3, 4]}\n\nmodel6 = gridsearchcv(model6, grid6, train_X, train_Y, dev_X, dev_Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8f444200fabf1930545d3d618a473bd175372db0"
      },
      "cell_type": "code",
      "source": "pickle.dump(model6, open('model6.sav', 'wb'))\nmodel6_load = pickle.load(open('model6.sav', 'rb'))\ny6 = model6_load.predict(test_X)\ny6_save = pd.DataFrame(data=[test_X_og.index, y6]).T\ny6_save.columns = ['PassengerId', 'Survived']\ny6_save = y6_save.astype('int32')\ny6_save.to_csv('y6.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "df4dbcdbd6f5e8bb5569237106ba82669d422b86"
      },
      "cell_type": "markdown",
      "source": "## Model 07 - AdaBoostClassifier"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2f0343ef4eb92de3144dbe57010e3808e6e6c7c6"
      },
      "cell_type": "code",
      "source": "model7 = ensemble.AdaBoostClassifier(base_estimator=model6.estimator, random_state=42)\n\ngrid7 = {'n_estimators' : [30, 40, 50, 60, 70], \n        'learning_rate' : [0.001, 0.01, 1]}\n\nmodel7 = gridsearchcv(model7, grid7, train_X, train_Y, dev_X, dev_Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02bd551457c8de278385d9dc63152757d1a40247"
      },
      "cell_type": "code",
      "source": "pickle.dump(model7, open('model7.sav', 'wb'))\nmodel7_load = pickle.load(open('model7.sav', 'rb'))\ny7 = model7_load.predict(test_X)\ny7_save = pd.DataFrame(data=[test_X_og.index, y7]).T\ny7_save.columns = ['PassengerId', 'Survived']\ny7_save = y7_save.astype('int32')\ny7_save.to_csv('y7.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LBPuihkn_QQo",
        "_uuid": "df73f6746fd3c17877347dc186601fd2e4c56fdf"
      },
      "cell_type": "markdown",
      "source": "## Model 08 - GradientBoostingClassifier"
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2ri9XLBp_QQo",
        "_uuid": "56e4431bfa27512511958a16f522f8d4a3499948",
        "trusted": true
      },
      "cell_type": "code",
      "source": "model8 = ensemble.GradientBoostingClassifier(criterion='friedman_mse', n_estimators=100, \n                                             n_iter_no_change=5, random_state=42)\ngrid8 = {'loss' : ['deviance', 'exponential'], \n        'learning_rate' : [0.001, 0.01, 1], \n        'min_samples_split' : [2, 3, 4, 5, 6], \n        'min_samples_leaf' : [1, 2, 3, 4, 5], \n        'max_depth' : [2, 3, 4, 5, 6]}\n\nmodel8 = gridsearchcv(model8, grid8, train_X, train_Y, dev_X, dev_Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0pagcXDZ_QQo",
        "_uuid": "71c0bc234d9997e01db35f326e54ae99b41927a5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "pickle.dump(model8, open('model8.sav', 'wb'))\nmodel8_load = pickle.load(open('model8.sav', 'rb'))\ny8 = model8_load.predict(test_X)\ny8_save = pd.DataFrame(data=[test_X_og.index, y8]).T\ny8_save.columns = ['PassengerId', 'Survived']\ny8_save = y8_save.astype('int32')\ny8_save.to_csv('y8.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "RyhBN2ep_QQo",
        "_uuid": "ccfa0ab5a8285d8b7549ae200cdadc847c181aef"
      },
      "cell_type": "markdown",
      "source": "## Model 09 - XGBClassifier"
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "1VYBkv4A_QSM",
        "_uuid": "d5d563c7298bff6d2bb72ce9ed02cc91ca45dc94",
        "trusted": true
      },
      "cell_type": "code",
      "source": "model9 = XGBClassifier(objective='binary:logistic', eval_metric='error', gamma=0.0001, \n                       n_estimators=100, verbosity=2, random_state=42)\n\ngrid9 = {'max_depth' : [2, 3, 4, 5, 6], \n        'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 1]}\n\nmodel9 = gridsearchcv(model9, grid9, train_X, train_Y, dev_X, dev_Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "psWI0YCh_QSM",
        "_uuid": "978eef5a2a3be628a704a42272821381c2f35aa4",
        "trusted": true
      },
      "cell_type": "code",
      "source": "pickle.dump(model9, open('model9.sav', 'wb'))\nmodel9_load = pickle.load(open('model9.sav', 'rb'))\ny9 = model9_load.predict(test_X)\ny9_save = pd.DataFrame(data=[test_X_og.index, y9]).T\ny9_save.columns = ['PassengerId', 'Survived']\ny9_save = y9_save.astype('int32')\ny9_save.to_csv('y9.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "44c5c7a12e1532af6a448b1c9ee22d81059784c9"
      },
      "cell_type": "markdown",
      "source": "## Model 10 - VotingClassifier"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d078a4385a0fc8f0e73fc4a9d2d8b0cadc5d5f3"
      },
      "cell_type": "code",
      "source": "model1_load = pickle.load(open('../input/model1.sav', 'rb'))\nmodel2_load = pickle.load(open('../input/model2.sav', 'rb'))\nmodel3_load = pickle.load(open('../input/model3.sav', 'rb'))\nmodel4_load = pickle.load(open('../input/model4.sav', 'rb'))\nmodel5_load = pickle.load(open('../input/model5.sav', 'rb'))\nmodel6_load = pickle.load(open('../input/model6.sav', 'rb'))\nmodel7_load = pickle.load(open('../input/model7.sav', 'rb'))\nmodel8_load = pickle.load(open('../input/model8.sav', 'rb'))\nmodel9_load = pickle.load(open('../input/model9.sav', 'rb'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f4b71fd6b2f31ac237e8bf4870a2fc8c60efb3f"
      },
      "cell_type": "code",
      "source": "estimators = [('model1', model1_load.estimator), ('model2', model2_load.estimator), \n              ('model3', model3_load.estimator), ('model4', model4_load.estimator), \n              ('model5', model5_load.estimator), ('model6', model6_load.estimator), \n              ('model7', model7_load.estimator), ('model8', model8_load.estimator), \n              ('model9', model9_load.estimator)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "8f05fd15da393026fc52005f7b4846ada0d66100"
      },
      "cell_type": "code",
      "source": "model10 = ensemble.VotingClassifier(estimators=estimators, voting='hard')\n\ngrid10 = {}\n\nmodel10 = gridsearchcv(model10, grid10, train_X, train_Y, dev_X, dev_Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HAoX9nFQ_QSM",
        "trusted": true,
        "_uuid": "413691e5349e08f8b8fa704b61d3a1c985019e2f"
      },
      "cell_type": "code",
      "source": "pickle.dump(model10, open('model10.sav', 'wb'))\nmodel10_load = pickle.load(open('model10.sav', 'rb'))\ny10 = model10_load.predict(test_X)\ny10_save = pd.DataFrame(data=[test_X_og.index, y10]).T\ny10_save.columns = ['PassengerId', 'Survived']\ny10_save = y10_save.astype('int32')\ny10_save.to_csv('y10.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YeGF5sC0_QSM",
        "trusted": false,
        "_uuid": "bbe5f7dec89976d7f13e709c0fe42f93f7ffeabe"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-wneOHmA_QSM",
        "trusted": false,
        "_uuid": "1e731bbc0673bbc5bb323b1e24d8a8b4ba3f2254"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "titanic_v1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}